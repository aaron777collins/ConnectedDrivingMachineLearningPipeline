2023-01-03 00:12:34.469709: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-01-03 00:12:39.668571: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-01-03 00:13:13.686338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-01-03 00:13:13.861107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-01-03 00:13:13.861148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-01-03 00:14:44.720957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2023-01-03 00:14:44.723730: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2023-01-03 00:14:44.723964: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bl12419.int.ets1.calculquebec.ca): /proc/driver/nvidia/version does not exist
2023-01-03 00:14:44.730703: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Creating Logger for model with id:SC-concat
### 2023-01-03_00-13-59 ### 
Getting ground truth file...[1/4] 
Converting test json files to csv files and expanding columns...[2/4] 
Cleaning data...[3/4] 
Done! 
First result: 
        rcvTime      sendTime  sender  ...  aclYNeg  hedXNeg  hedYNeg
0  53116.156561  53116.156561  4989.0  ...        1        1        1
1  53116.159207  53116.159207  4905.0  ...        1        0        0
2  53116.186748  53116.186748  4671.0  ...        0        0        1
3  53116.251014  53116.251014  4995.0  ...        1        0        0
4  53116.562243  53116.562243  5013.0  ...        1        1        1

[5 rows x 22 columns] 
(633, 22) 
Merging... [4/4] 
Done! 
        rcvTime      sendTime  sender  ...  aclYNeg  hedXNeg  hedYNeg
0  53116.156561  53116.156561  4989.0  ...        1        1        1
1  53116.159207  53116.159207  4905.0  ...        1        0        0
2  53116.186748  53116.186748  4671.0  ...        0        0        1
3  53116.251014  53116.251014  4995.0  ...        1        0        0
4  53116.562243  53116.562243  5013.0  ...        1        1        1

[5 rows x 22 columns] 
(100897, 22) 
Quick stats on clean, merged and sorted data 
        rcvTime      sendTime  sender  ...  aclYNeg  hedXNeg  hedYNeg
0  53116.156561  53116.156561  4989.0  ...        1        1        1
1  53116.159207  53116.159207  4905.0  ...        1        0        0
2  53116.186748  53116.186748  4671.0  ...        0        0        1
3  53116.251014  53116.251014  4995.0  ...        1        0        0
4  53116.562243  53116.562243  5013.0  ...        1        1        1

[5 rows x 22 columns]
(100897, 22)
Getting Data Sets.. 
Time elapsed: (hh:mm:ss:ms) 0:00:00.006301 
Quick stats on features and answers for the train-val-test split 
        rcvTime      sendTime  sender  ...  aclYNeg  hedXNeg  hedYNeg
0  53116.156561  53116.156561  4989.0  ...        1        1        1
1  53116.159207  53116.159207  4905.0  ...        1        0        0
2  53116.186748  53116.186748  4671.0  ...        0        0        1
3  53116.251014  53116.251014  4995.0  ...        1        0        0
4  53116.562243  53116.562243  5013.0  ...        1        1        1

[5 rows x 21 columns]
(80716, 21)
   isAttacker
0           0
1           0
2           0
3           0
4           0
(80716, 1)
            rcvTime      sendTime  sender  ...  aclYNeg  hedXNeg  hedYNeg
80716  51093.174813  51093.174813  1359.0  ...        0        1        1
80717  51094.174813  51094.174813  1359.0  ...        0        1        1
80718  51095.174815  51095.174815  1359.0  ...        1        1        1
80719  51096.174811  51096.174811  1359.0  ...        1        1        1
80720  51097.174820  51097.174820  1359.0  ...        1        1        1

[5 rows x 21 columns]
(20181, 21)
       isAttacker
80716           0
80717           0
80718           0
80719           0
80720           0
(20181, 1)
Verifying the features and answers for the sets add up 
Adding up X 
Sum: 1.0 
Adding up Y 
Sum: 1.0 
Building LSTM 
Building Model on: LSTM 
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 21, 1000)          1300000000
                                                       0         
                                                                 
 lstm (LSTM)                 (None, 128)               578048    
                                                                 
 dense (Dense)               (None, 2)                 258       
                                                                 
=================================================================
Total params: 13,000,578,306
Trainable params: 13,000,578,306
Non-trainable params: 0
_________________________________________________________________
Epoch 1/2
Traceback (most recent call last):
  File "/lustre03/project/6063935/colli11s/ConnectedDrivingMachineLearningPipeline/ModelTrainerSCSortedByTimeLSTM.py", line 327, in <module>
    ModelTrainerSCSortedByTimeLSTM().main()
  File "/lustre03/project/6063935/colli11s/ConnectedDrivingMachineLearningPipeline/ModelTrainerSCSortedByTimeLSTM.py", line 226, in main
    [model, history] = self.buildModel(X_train, Y_train, self.get_compiled_model())
  File "/lustre03/project/6063935/colli11s/ConnectedDrivingMachineLearningPipeline/ModelTrainerSCSortedByTimeLSTM.py", line 321, in buildModel
    history = model.fit(features, answers, batch_size=BATCH_SIZE, epochs=EPOCHS)
  File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/tmp/__autograph_generated_file7most37s.py", line 15, in tf__train_function
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError: in user code:

    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/engine/training.py", line 1160, in train_function  *
        return step_function(self, iterator)
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/engine/training.py", line 1146, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/engine/training.py", line 1135, in run_step  **
        outputs = model.train_step(data)
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/engine/training.py", line 994, in train_step
        loss = self.compute_loss(x, y, y_pred, sample_weight)
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/engine/training.py", line 1052, in compute_loss
        return self.compiled_loss(
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/engine/compile_utils.py", line 265, in __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/losses.py", line 152, in __call__
        losses = call_fn(y_true, y_pred)
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/losses.py", line 272, in call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/losses.py", line 2162, in binary_crossentropy
        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),
    File "/home/colli11s/ENV/lib/python3.10/site-packages/keras/backend.py", line 5677, in binary_crossentropy
        return tf.nn.sigmoid_cross_entropy_with_logits(

    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).

